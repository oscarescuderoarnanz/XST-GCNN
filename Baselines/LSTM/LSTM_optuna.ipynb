{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad31f2d8-461a-4b1b-b291-3c3398d5b761",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "\n",
    "import random, os, json\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Masking, GRU, Dropout, Dense\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "\n",
    "import pickle\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e72dea-acfc-45a8-b140-8a1521095f87",
   "metadata": {},
   "source": [
    "### FUNCTIONS OF THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04f6163-a4d3-4304-af75-c4898fc64c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_keras(seed=42):\n",
    "    \"\"\"Function to ensure that results from Keras models\n",
    "    are consistent and reproducible across different runs\"\"\"\n",
    "    \n",
    "    K.clear_session()\n",
    "    # 1. Set `PYTHONHASHSEED` environment variable at a fixed value\n",
    "    os.environ['PYTHONHASHSEED']=str(seed)\n",
    "    # 2. Set `python` built-in pseudo-random generator at a fixed value\n",
    "    random.seed(seed)\n",
    "    # 3. Set `numpy` pseudo-random generator at a fixed value\n",
    "    np.random.seed(seed)\n",
    "    # 4. Set `tensorflow` pseudo-random generator at a fixed value\n",
    "    tf.random.set_seed(seed)\n",
    "    \n",
    "def build_model(hyperparameters):\n",
    "    \"\"\"\n",
    "    Builds a GRU model based on several hyperparameters.\n",
    "\n",
    "    Args:\n",
    "        - hyperparameters: Dictionary containing the model hyperparameters. \n",
    "    Returns:\n",
    "        - model: A tf.keras.Model with the compiled model.\n",
    "    \"\"\"\n",
    "    hyperparameters['layers'] = [80, hyperparameters['middle_layer_dim'], 1]\n",
    "    l2_lambda = hyperparameters.get(\"l2_lambda\", 1e-4)\n",
    "    \n",
    "    dynamic_input = tf.keras.layers.Input(shape=(hyperparameters[\"n_time_steps\"], hyperparameters[\"layers\"][0]))\n",
    "    masked = tf.keras.layers.Masking(mask_value=hyperparameters['mask_value'])(dynamic_input)\n",
    "    optimizer = Adam(learning_rate=hyperparameters[\"lr_scheduler\"], weight_decay=hyperparameters[\"weight_decay\"])\n",
    "\n",
    "    gru_encoder = tf.keras.layers.LSTM(\n",
    "        hyperparameters[\"layers\"][1],\n",
    "        dropout=hyperparameters['dropout'],\n",
    "        return_sequences=False,\n",
    "        activation=hyperparameters['activation'],\n",
    "        kernel_regularizer=regularizers.l2(l2_lambda),\n",
    "        use_bias=False\n",
    "    )(masked)\n",
    "\n",
    "    if hyperparameters['dropout'] > 0.0:\n",
    "        gru_encoder = tf.keras.layers.Dropout(hyperparameters['dropout'])(gru_encoder)\n",
    "\n",
    "    output = tf.keras.layers.Dense(1, use_bias=False, activation=\"sigmoid\",kernel_regularizer=regularizers.l2(l2_lambda))(gru_encoder)\n",
    "\n",
    "    model = tf.keras.Model(dynamic_input, output)\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer=optimizer,\n",
    "        metrics=['accuracy', \"AUC\"], weighted_metrics = []\n",
    "    )\n",
    "        \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a5e399-a66f-4328-bc92-a8db8f5e33a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_network(X_train, X_val, y_train, y_val, \n",
    "                hyperparameters, seed):\n",
    "    \"\"\"\n",
    "    Trains and evaluates the built GRU model based on the provided data and hyperparameters.\n",
    "\n",
    "    Args:\n",
    "        - X_train, X_val, y_train, y_val: numpy.ndarray. Training (T) and Validation (V) data labels.\n",
    "        - hyperparameters: Dictionary containing training and model hyperparameters.\n",
    "        - seed: Random seed for reproducibility.\n",
    "    Returns:\n",
    "        - model (tf.keras.Model): The trained Keras model.\n",
    "        - hist (tf.keras.callbacks.History): Training history object containing loss and metrics.\n",
    "        - training_time (float): Total training time in seconds.\n",
    "    \"\"\"\n",
    "\n",
    "    model = None\n",
    "    model = build_model(hyperparameters)\n",
    "    earlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                  min_delta=hyperparameters[\"mindelta\"],\n",
    "                                                  patience=hyperparameters[\"patience\"],\n",
    "                                                  restore_best_weights=True,\n",
    "                                                  mode=\"min\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    hist = model.fit(X_train, y_train,\n",
    "                     validation_data=(X_val, y_val),\n",
    "                     callbacks=[earlystopping], batch_size=hyperparameters['batch_size'], epochs=hyperparameters['n_epochs_max'],\n",
    "                     verbose=hyperparameters['verbose'])\n",
    "    \n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "\n",
    "    return model, hist, training_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ea3a15-d2b1-4ed3-8e99-d5bdc1311db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, hyperparameters, seed, X_train, y_train, X_val, y_val, split, norm, n_time_steps):\n",
    "    \"\"\"\n",
    "    Objective function for hyperparameter optimization using Optuna.\n",
    "    Args:\n",
    "        - trial (optuna.trial.Trial): Optuna trial object.\n",
    "        - X_train, X_val, y_train, y_val: numpy.ndarray. Training (T) and Validation (V) data labels.\n",
    "        - hyperparameters: Dictionary containing training and model hyperparameters.\n",
    "        - seed: Random seed for reproducibility.  \n",
    "        - split: String indicating the data split.\n",
    "        - norm: String with the type of normalization applied to the data.\n",
    "        - n_time_steps: Number of time steps in the input.    \n",
    "    Returns:\n",
    "        - metric_dev (float): Best validation loss   \n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"Trial {trial.number} started\")\n",
    "    hyperparameters_copy = hyperparameters.copy()\n",
    "\n",
    "    hyperparameters_copy[\"dropout\"] = trial.suggest_float('dropout', 0.0, 0.3)\n",
    "    middle_dim = trial.suggest_int('middle_layer_dim', 2, 50, step=2)\n",
    "    hyperparameters_copy['middle_layer_dim'] = middle_dim\n",
    "    hyperparameters_copy[\"lr_scheduler\"] = trial.suggest_loguniform('lr_scheduler', 1e-3, 1e-1)\n",
    "    hyperparameters_copy[\"l2_lambda\"] = trial.suggest_loguniform('l2_lambda', 1e-6, 1e-2)\n",
    "    hyperparameters_copy[\"adjustment_factor\"] = trial.suggest_categorical('adjustment_factor', [1])\n",
    "    hyperparameters_copy[\"activation\"] = trial.suggest_categorical('activation', ['LeakyReLU', 'tanh'])\n",
    "    hyperparameters_copy['patience'] = trial.suggest_int('patience', 1, 50)\n",
    "    hyperparameters_copy['mindelta'] = trial.suggest_loguniform('mindelta', 1e-10, 1e-3)\n",
    "    hyperparameters_copy[\"weight_decay\"] = trial.suggest_loguniform('weight_decay', 1e-5, 0)\n",
    "    \n",
    "\n",
    "    hyperparameters_copy['batch_size'] = hyperparameters['batch_size']\n",
    "    hyperparameters_copy['n_epochs_max'] = hyperparameters['n_epochs_max']\n",
    "   \n",
    "    v_val_loss = []\n",
    "        \n",
    "\n",
    "    model, hist, training_time = run_network(\n",
    "            X_train, X_val,\n",
    "            y_train,\n",
    "            y_val,\n",
    "            hyperparameters_copy,\n",
    "            seed\n",
    "    )\n",
    "\n",
    "    v_val_loss.append(np.min(hist.history[\"val_loss\"]))\n",
    "\n",
    "    metric_dev = np.mean(v_val_loss)\n",
    "    return metric_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9f881e-b237-4631-b9a8-185c6cc4a44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optuna_study(hyperparameters, seed, X_train, y_train, X_val, y_val, split, norm, n_time_steps):\n",
    "    \"\"\"\n",
    "    Runs an Optuna study to optimize hyperparameters for the model.\n",
    "    \n",
    "    Args:\n",
    "        - X_train, X_val, y_train, y_val: numpy.ndarray. Training (T) and Validation (V) data labels.\n",
    "        - hyperparameters: Dictionary containing training and model hyperparameters.\n",
    "        - seed: Random seed for reproducibility.  \n",
    "        - split: String indicating the data split.\n",
    "        - norm: String with the type of normalization applied to the data.\n",
    "        - n_time_steps: Number of time steps in the input.       \n",
    "    Returns:\n",
    "        - best_hyperparameters: Dictionary containing the best hyperparameters found \n",
    "          after the optimization process.\n",
    "    \"\"\"\n",
    "    sampler = optuna.samplers.TPESampler(seed=42)\n",
    "    study = optuna.create_study(direction='minimize', sampler=sampler)\n",
    "    \n",
    "    study.optimize(lambda trial: objective(trial, hyperparameters, seed, X_train, y_train , X_val, y_val, split, norm, n_time_steps), n_trials=30)\n",
    "    \n",
    "    best_params = study.best_params\n",
    "    best_metric = study.best_value\n",
    "    \n",
    "    layers = [80, best_params['middle_layer_dim'], 1]\n",
    "    \n",
    "    best_hyperparameters = {\n",
    "        'dropout': best_params['dropout'],\n",
    "        'middle_layer_dim': best_params['middle_layer_dim'],\n",
    "        'layers': layers,\n",
    "        'lr_scheduler': best_params['lr_scheduler'],\n",
    "        'l2_lambda': best_params['l2_lambda'],\n",
    "        'adjustment_factor': best_params['adjustment_factor'],\n",
    "        'activation': best_params['activation'],\n",
    "        'batch_size': hyperparameters['batch_size'],\n",
    "        'n_epochs_max': hyperparameters['n_epochs_max'],\n",
    "        'patience': best_params['patience'],\n",
    "        'mindelta': best_params['mindelta'],\n",
    "        'weight_decay': best_params['weight_decay']\n",
    "    }\n",
    "    \n",
    "\n",
    "    print(f\"Best Hyperparameters: {best_params}\")\n",
    "    print(f\"Best Validation Metric: {best_metric}\")\n",
    "\n",
    "    return best_hyperparameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db3d036-d378-4070-9fca-3b054b8c8bfd",
   "metadata": {},
   "source": [
    "### HYPERPARAMETERS "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea21a27-ba5a-4b31-9ac2-ef2de69305d4",
   "metadata": {},
   "source": [
    "- **seeds**: Seed values to ensure reproducibility.\n",
    "- **input_shape**: Number of features in each time step of the input data.\n",
    "- **n_time_steps**: Number of time steps in the input sequence.\n",
    "- **batch_size**: Number of batches for training.\n",
    "- **norm**: Type of normalization applied to the data.\n",
    "- **dropout**: Dropout rate to prevent overfitting.\n",
    "- **l2_lambda**: L2 regularization coefficient.\n",
    "- **lr_scheduler**: Learning rate assigned to the optimizer.\n",
    "- **patience**: Number of epochs with no improvement before early stopping is triggered.\n",
    "- **weight_decay**: Weight decay for the optimizer to apply additional L2 regularization on weights.\n",
    "- **middle_layer_dim**: Different configurations for the middle layer of the model.\n",
    "- **mindelta**: Minimum delta required to consider as an improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f0a288-018e-4fad-bbf4-2be13135a2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = [42, 76, 124, 163, 192, 205]\n",
    "\n",
    "input_shape = 80\n",
    "n_time_steps = 14\n",
    "batch_size = 32\n",
    "n_epochs_max = 1000\n",
    "\n",
    "adjustment_factor = [1]  \n",
    "activation = ['LeakyReLU']\n",
    "norm = \"robustNorm\"\n",
    "patience = 3  \n",
    "monitor = \"val_loss\"   \n",
    "\n",
    "hyperparameters = {\n",
    "    \"n_time_steps\": n_time_steps,\n",
    "    \"mask_value\": 666,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"n_epochs_max\": n_epochs_max,\n",
    "    \"monitor\": monitor,\n",
    "    \"mindelta\": 0,\n",
    "    \"patience\": patience,\n",
    "    \"dropout\": 0.2,\n",
    "    \"l2_lambda\": 1e-4,\n",
    "    \"verbose\": 1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2dc37e-323b-486b-a0b7-a62d3f6d79b4",
   "metadata": {},
   "source": [
    "### PREDICTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f94d65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_model = True\n",
    "debug = True\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    average_precision_score,\n",
    ")\n",
    "\n",
    "if run_model:\n",
    "    import time\n",
    "\n",
    "    loss_train = []\n",
    "    loss_dev = []\n",
    "    v_models = []\n",
    "    training_times = []\n",
    "    optimization_times = []\n",
    "    inference_times = []\n",
    "\n",
    "    v_accuracy_test = []\n",
    "    v_specificity = []\n",
    "    v_precision = []\n",
    "    v_recall = []\n",
    "    v_f1score = []\n",
    "    v_roc = []\n",
    "    v_aucpr = []\n",
    "\n",
    "    bestHyperparameters_bySplit = {}\n",
    "    y_pred_by_split = {}\n",
    "    results = \"\"\n",
    "\n",
    "    for i in [1, 2, 3]:\n",
    "        print(\"====================>\", i)\n",
    "\n",
    "\n",
    "        X_train = np.load(f\"../../DATA/s{i}/X_train_tensor_robustNorm.npy\")\n",
    "        X_val = np.load(f\"../../DATA/s{i}/X_val_tensor_robustNorm.npy\")\n",
    "\n",
    "        y_train = pd.read_csv(f\"../../DATA/s{i}/y_train_robustNorm.csv\")[['individualMRGerm_stac']]\n",
    "        y_train = y_train.iloc[0:y_train.shape[0]:hyperparameters[\"n_time_steps\"]].reset_index(drop=True)\n",
    "\n",
    "        y_val = pd.read_csv(f\"../../DATA/s{i}/y_val_robustNorm.csv\")[['individualMRGerm_stac']]\n",
    "        y_val = y_val.iloc[0:y_val.shape[0]:hyperparameters[\"n_time_steps\"]].reset_index(drop=True)\n",
    "\n",
    "        X_test = np.load(f\"../../DATA/s{i}/X_test_tensor_robustNorm.npy\")\n",
    "        y_test = pd.read_csv(f\"../../DATA/s{i}/y_test_robustNorm.csv\")[['individualMRGerm_stac']]\n",
    "        y_test = y_test.iloc[0:y_test.shape[0]:hyperparameters[\"n_time_steps\"]].reset_index(drop=True)\n",
    "\n",
    "\n",
    "        start_opt = time.time()\n",
    "        bestHyperparameters = optuna_study(\n",
    "            hyperparameters,\n",
    "            seeds[i-1],\n",
    "            X_train, y_train,  \n",
    "            X_val, y_val,\n",
    "            f\"s{i}\",\n",
    "            norm,\n",
    "            n_time_steps\n",
    "        )\n",
    "        end_opt = time.time()\n",
    "        optimization_times.append(end_opt - start_opt)\n",
    "\n",
    "        print(f\"Best layers: {bestHyperparameters['layers']}\")\n",
    "        bestHyperparameters_bySplit[str(i)] = bestHyperparameters\n",
    "\n",
    "\n",
    "        split_directory = f'./Results_LSTM_optuna/split_{i}'\n",
    "        os.makedirs(split_directory, exist_ok=True)\n",
    "        with open(os.path.join(split_directory, f\"bestHyperparameters_split_{i}.pkl\"), 'wb') as f:\n",
    "            pickle.dump(bestHyperparameters, f)\n",
    "\n",
    "        hyperparameters.update({\n",
    "            \"dropout\": bestHyperparameters[\"dropout\"],\n",
    "            \"layers\": bestHyperparameters[\"layers\"],\n",
    "            \"lr_scheduler\": bestHyperparameters[\"lr_scheduler\"],\n",
    "            \"l2_lambda\": bestHyperparameters[\"l2_lambda\"],\n",
    "            \"adjustment_factor\": bestHyperparameters[\"adjustment_factor\"],\n",
    "            \"activation\": bestHyperparameters[\"activation\"], \n",
    "            \"patience\": bestHyperparameters[\"patience\"], \n",
    "            \"weight_decay\": bestHyperparameters[\"weight_decay\"],\n",
    "            \"mindelta\": bestHyperparameters[\"mindelta\"],\n",
    "            \"middle_layer_dim\": bestHyperparameters[\"middle_layer_dim\"]\n",
    "        })\n",
    "\n",
    "\n",
    "        reset_keras()\n",
    "        print(hyperparameters)\n",
    "\n",
    "\n",
    "        start_train = time.time()\n",
    "        model, hist, training_time = run_network(\n",
    "            X_train, X_val,\n",
    "            y_train, \n",
    "            y_val,\n",
    "            hyperparameters,\n",
    "            seeds[i-1]\n",
    "        )\n",
    "        end_train = time.time()\n",
    "        training_times.append(end_train - start_train)\n",
    "\n",
    "        v_models.append(model)\n",
    "        loss_train.append(hist.history['loss'])\n",
    "        loss_dev.append(hist.history['val_loss'])\n",
    "\n",
    "\n",
    "        start_inf = time.time()\n",
    "        y_pred = model.predict(x=X_test)\n",
    "        end_inf = time.time()\n",
    "        inference_times.append(end_inf - start_inf)\n",
    "\n",
    "        y_pred_by_split[str(i)] = y_pred\n",
    "        with open(os.path.join(split_directory, f\"y_pred_split_{i}.pkl\"), 'wb') as f:\n",
    "            pickle.dump(y_pred, f)\n",
    "\n",
    "        model.save(os.path.join(split_directory, f\"model_split_{i}.h5\"))\n",
    "\n",
    "\n",
    "        accuracy_test = accuracy_score(y_test, np.round(y_pred))\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, np.round(y_pred)).ravel()\n",
    "        roc = roc_auc_score(y_test, y_pred)\n",
    "        aucpr = average_precision_score(y_test, y_pred)\n",
    "\n",
    "        v_accuracy_test.append(accuracy_test)\n",
    "        v_specificity.append(tn / (tn + fp))\n",
    "        v_precision.append(tp / (tp + fp))\n",
    "        v_recall.append(tp / (tp + fn))\n",
    "        v_f1score.append((2 * v_recall[i - 1] * v_precision[i - 1]) / (v_recall[i - 1] + v_precision[i - 1]))\n",
    "        v_roc.append(roc)\n",
    "        v_aucpr.append(aucpr)\n",
    "\n",
    "        if debug:\n",
    "            results += f\"\\tSplit {i} - Timing (s):\\n\"\n",
    "            results += f\"\\t\\tOptimization: {optimization_times[-1]:.2f}\\n\"\n",
    "            results += f\"\\t\\tTraining: {training_times[-1]:.2f}\\n\"\n",
    "            results += f\"\\t\\tInference: {inference_times[-1]:.2f}\\n\"\n",
    "            results += f\"\\t\\tTP: {tp} | FP: {fp} | TN: {tn} | FN: {fn}\\n\"\n",
    "            results += f\"\\t\\tAccuracy: {accuracy_test:.4f} | ROC-AUC: {roc:.4f} | AUC-PR: {aucpr:.4f}\\n\"\n",
    "\n",
    "\n",
    "    directory = './Results_LSTM_optuna'\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    summary_df = pd.DataFrame({\n",
    "        \"Split\": [i for i in range(1, len(v_accuracy_test) + 1)],\n",
    "        \"OptimizationTime\": optimization_times,\n",
    "        \"TrainingTime\": training_times,\n",
    "        \"InferenceTime\": inference_times,\n",
    "        \"Accuracy\": v_accuracy_test,\n",
    "        \"Specificity\": v_specificity,\n",
    "        \"Precision\": v_precision,\n",
    "        \"Recall\": v_recall,\n",
    "        \"F1Score\": v_f1score,\n",
    "        \"ROC_AUC\": v_roc,\n",
    "        \"AUC_PR\": v_aucpr\n",
    "    })\n",
    "\n",
    "    summary_path = os.path.join(directory, \"summary_metrics.csv\")\n",
    "    summary_df.to_csv(summary_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70905f1a",
   "metadata": {},
   "source": [
    "## RESULTS (PERFORMANCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19708712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity: 67.92 +- 2.67\n",
      "Specificity: 80.36 +- 2.22\n",
      "Precision: 38.31 +- 1.95\n",
      "F1-score: 48.92 +- 1.33\n",
      "ROC-AUC: 75.68 +- 1.23\n",
      "AUC-PR: 46.49 +- 3.22\n",
      "Test Accuracy: 78.48 +- 1.59\n",
      "\n"
     ]
    }
   ],
   "source": [
    "directory = './Results_LSTM_optuna'\n",
    "summary_path = os.path.join(directory, \"summary_metrics.csv\")\n",
    "summary_df = pd.read_csv(summary_path)\n",
    "\n",
    "\n",
    "def calculateKPI(parameter):\n",
    "    \"\"\"\n",
    "    This function calculate the mean and deviation of a set of values of\n",
    "    a given performance indicator.\n",
    "    \n",
    "    Returns: Mean and std (float)\n",
    "    \"\"\"\n",
    "    mean = round(np.mean(parameter)*100, 2)\n",
    "    deviation = round(np.sqrt(np.sum(np.power(parameter - np.mean(parameter), 2) / len(parameter)))*100, 2)\n",
    "    return mean, deviation\n",
    "\n",
    "def format_metric_line(metric_name, mean_value, deviation_value):\n",
    "    return f\"{metric_name}: {mean_value:.2f} +- {deviation_value:.2f}\\n\"\n",
    "\n",
    "mean_test, deviation_test = calculateKPI(summary_df[\"Accuracy\"])\n",
    "mean_specificity, deviation_specificity = calculateKPI(summary_df[\"Specificity\"])\n",
    "mean_recall, deviation_recall = calculateKPI(summary_df[\"Recall\"])\n",
    "mean_f1, deviation_f1 = calculateKPI(summary_df[\"F1Score\"])\n",
    "mean_precision, deviation_precision = calculateKPI(summary_df[\"Precision\"])\n",
    "mean_roc, deviation_roc = calculateKPI(summary_df[\"ROC_AUC\"])\n",
    "mean_aucpr, deviation_aucpr = calculateKPI(summary_df[\"AUC_PR\"])  \n",
    "\n",
    "results = \"\"\n",
    "results += format_metric_line(\"Test Accuracy\", mean_test, deviation_test)\n",
    "results += format_metric_line(\"Specificity\", mean_specificity, deviation_specificity)\n",
    "results += format_metric_line(\"Sensitivity\", mean_recall, deviation_recall)\n",
    "results += format_metric_line(\"Precision\", mean_precision, deviation_precision)\n",
    "results += format_metric_line(\"F1-score\", mean_f1, deviation_f1)\n",
    "results += format_metric_line(\"ROC-AUC\", mean_roc, deviation_roc)\n",
    "results += format_metric_line(\"AUC-PR\", mean_aucpr, deviation_aucpr) \n",
    "\n",
    "final_results = (\n",
    "    f\"Sensitivity: {mean_recall:.2f} +- {deviation_recall:.2f}\\n\"\n",
    "    f\"Specificity: {mean_specificity:.2f} +- {deviation_specificity:.2f}\\n\"\n",
    "    f\"Precision: {mean_precision:.2f} +- {deviation_precision:.2f}\\n\"\n",
    "    f\"F1-score: {mean_f1:.2f} +- {deviation_f1:.2f}\\n\"\n",
    "    f\"ROC-AUC: {mean_roc:.2f} +- {deviation_roc:.2f}\\n\"\n",
    "    f\"AUC-PR: {mean_aucpr:.2f} +- {deviation_aucpr:.2f}\\n\" \n",
    "    f\"Test Accuracy: {mean_test:.2f} +- {deviation_test:.2f}\\n\"\n",
    ")\n",
    "\n",
    "print(final_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7a3d46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
