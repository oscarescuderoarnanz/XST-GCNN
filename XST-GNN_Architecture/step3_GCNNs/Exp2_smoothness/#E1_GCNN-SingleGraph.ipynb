{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d118f8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# My libraries\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0896ac",
   "metadata": {},
   "source": [
    "## General parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688bde93",
   "metadata": {},
   "outputs": [],
   "source": [
    "numberOfTimeStep = 14\n",
    "folders = [\"s1\", \"s2\", \"s3\"]\n",
    "\n",
    "norm = \"robustNorm\"\n",
    "build_grapb_by = \"dtw-gower\"\n",
    "\n",
    "device = torch.device('cuda:1')\n",
    "print(\"Seleccionando la segunda GPU:\", torch.cuda.get_device_name(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ea1b2f",
   "metadata": {},
   "source": [
    "## Train phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f581cec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Always the same values, do not touch. \n",
    "in_dim_GCN = 1\n",
    "out_dim_GCN = 1\n",
    "\n",
    "# number of max epochs \n",
    "n_epochs = 1000\n",
    "\n",
    "# Early stopping configuration\n",
    "early_stopping_patience = 50\n",
    "\n",
    "# Hyperparameters to be optimized (change this values)\n",
    "h_dropout = [0.0, 0.15, 0.3]\n",
    "h_learning_rate = [1e-3, 1e-2, 5e-2, 0.1]\n",
    "h_decay = [0, 1e-5, 1e-4, 1e-3, 1e-2]\n",
    "h_hid_lay = [4, 8, 16, 32, 64]\n",
    "h_layers = [1, 2, 3, 4, 5, 6]\n",
    "seed = [42, 76, 124, 163, 192, 205, 221, 245, 293]\n",
    "\n",
    "fc_layer = [[80, out_dim_GCN]]\n",
    "\n",
    "# Parameters to define type of GCNN and type of output.\n",
    "typeGCN = \"standard_gcnn\"\n",
    "K = [0]\n",
    "\n",
    "params = {# Hyperparameters\n",
    "         'h_layers':h_layers, 'n_epochs':n_epochs, \n",
    "          'h_dropout': h_dropout, 'h_learning_rate': h_learning_rate, \n",
    "          'h_decay':h_decay, 'h_hid_lay': h_hid_lay, 'K':K,\n",
    "          'fc_layer': fc_layer,\n",
    "          # seed to set initialization hyperparameters\n",
    "          'seed': seed, \n",
    "          # Type of output GCN\n",
    "          'typeGCN': typeGCN,\n",
    "          # Dimensions of GCN (input/output)\n",
    "          'in_dim_GCN': in_dim_GCN, 'out_dim_GCN': out_dim_GCN,\n",
    "          # Patiente\n",
    "          'early_stopping_patience':early_stopping_patience}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf7ac1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "way_to_build_graph = \"smoothness\"\n",
    "numberOfFeatures = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae68d7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "\n",
    "best_result_by_split = {}\n",
    "train_times_by_split = {}\n",
    "\n",
    "for carp in range(len(folders)):\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # Load data for the current split\n",
    "    X_train_vec, X_val_vec, X_test_vec, y_train, y_val, y_test = utils.load_data(norm, device, folders[carp], SG=True)\n",
    "    A = pd.read_csv(\"../../step2_graphRepresentation/\" + way_to_build_graph + \"/\" + folders[carp] + \"/ProdGraph_Xtr_\" + norm + \"_th_0.95.csv\")\n",
    "    A = A.iloc[0:numberOfFeatures, 0:numberOfFeatures]\n",
    "    A = torch.tensor(np.array(A), dtype=torch.float32)\n",
    "\n",
    "    print(f\"\\n===========> TRAIN-VAL PHASE for folder {folders[carp]} ==================\")\n",
    "\n",
    "    # Measure training time\n",
    "    start_time = time.time()\n",
    "    bestHyperparameters = utils.train_val_phase(A, X_train_vec, X_val_vec, y_train, y_val, params, device)\n",
    "    end_time = time.time()\n",
    "    elapsed_time = round(end_time - start_time, 2)\n",
    "\n",
    "    print(f\"<========== END TRAIN-VAL PHASE for folder {folders[carp]} | Elapsed time: {elapsed_time:.2f} seconds ==============\\n\")\n",
    "\n",
    "    # Store best hyperparameters\n",
    "    best_result_by_split[folders[carp]] = {\n",
    "        \"best_hyperparameters\": bestHyperparameters\n",
    "    }\n",
    "\n",
    "# Save best hyperparameters\n",
    "path_hyper = \"../hyperparameters/\" + way_to_build_graph + \"/#E1-SingleGraph_th_0.95.json\"\n",
    "utils.saveBestHyperparameters(best_result_by_split, path_hyper)\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f002292a",
   "metadata": {},
   "source": [
    "## Validation phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa871691",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "folders = [\"s1\", \"s2\", \"s3\"]\n",
    "best_result_by_split = utils.loadBestHyperparameters(\n",
    "    \"../hyperparameters/\" + way_to_build_graph + \"/#E1-SingleGraph_th_0.95.json\"\n",
    ")\n",
    "\n",
    "typeOfGraph = \"ProdGraph\"\n",
    "path_A = typeOfGraph + \"_Xtr_\" + norm + \"_th_0.975.csv\"  # File may still use 0.975 as suffix\n",
    "\n",
    "# Dictionary to store inference times\n",
    "inference_times_by_split = {}\n",
    "\n",
    "# Containers for results\n",
    "results = {}\n",
    "importance_nodes = {}\n",
    "fc_classifiers = {}\n",
    "gnn_models = {}\n",
    "\n",
    "# Inference loop per split\n",
    "for folder in folders:\n",
    "\n",
    "    start_time = time.time()\n",
    "    res, imp_nodes, fc_cls, gnn_mod = utils.val_model(\n",
    "        {folder: best_result_by_split[folder]},\n",
    "        typeOfGraph, params, [folder], norm, device, path_A, way_to_build_graph, SG=True\n",
    "    )\n",
    "    end_time = time.time()\n",
    "    elapsed = round(end_time - start_time, 2)\n",
    "\n",
    "    inference_times_by_split[folder] = {\n",
    "        \"inference_time_seconds\": elapsed\n",
    "    }\n",
    "\n",
    "    # Collect results\n",
    "    for k in res:\n",
    "        if k not in results:\n",
    "            results[k] = []\n",
    "        results[k].append(res[k][0])\n",
    "    importance_nodes[folder] = imp_nodes\n",
    "    fc_classifiers[folder] = fc_cls\n",
    "    gnn_models[folder] = gnn_mod\n",
    "\n",
    "# Print results per split\n",
    "keys = list(results.keys())\n",
    "for c in range(len(folders)):\n",
    "    print(\"================= SPLIT \" + str(folders[c]) + \" ===================\")\n",
    "    for k in keys:\n",
    "        print(k + \": \" + str(np.round(results[k][c] * 100, 2)))\n",
    "\n",
    "# Print average and standard deviation\n",
    "print()\n",
    "str_result = \"\"\n",
    "for k in keys:\n",
    "    avg = np.mean(results[k])\n",
    "    std = np.std(results[k])\n",
    "    print(f\"{k}: {np.round(avg * 100, 2)} +- {np.round(std * 100, 2)}\")\n",
    "\n",
    "    if k in [\"test_acc\", \"roc_auc\", \"auc_pr\"]:\n",
    "        str_result += f\"{np.round(avg * 100, 2)} +- {np.round(std * 100, 2)} & \"\n",
    "    elif k == \"specificity\":\n",
    "        str_result += f\"{np.round(avg * 100, 2)} +- {np.round(std * 100, 2)} \\\\\\ \"\n",
    "\n",
    "print(\"\\n\", str_result)\n",
    "\n",
    "# Save inference times to JSON file\n",
    "path_times = \"../hyperparameters/\" + way_to_build_graph + \"/#E1-InferenceTimes_th_0.95.json\"\n",
    "with open(path_times, 'w') as f:\n",
    "    json.dump(inference_times_by_split, f, indent=4)\n",
    "\n",
    "print(f\"\\nInference times saved to: {path_times}\")\n",
    "\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76adfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "72.7 +- 1.87 & 63.52 +- 2.35 & 70.15 +- 1.11 & 42.37 +- 2.21 \\\\ "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
