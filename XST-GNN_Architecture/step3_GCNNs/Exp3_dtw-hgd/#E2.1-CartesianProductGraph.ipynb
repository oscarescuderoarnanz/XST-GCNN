{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da26005d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# My libraries\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514e629c",
   "metadata": {},
   "outputs": [],
   "source": [
    "numberOfTimeStep = 14\n",
    "folders = [\"s1\", \"s2\", \"s3\"]\n",
    "norm = \"robustNorm\"\n",
    "\n",
    "device = torch.device('cuda:1')\n",
    "print(\"Seleccionando la primera GPU:\", torch.cuda.get_device_name(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be278ea",
   "metadata": {},
   "source": [
    "## Hyperparameteres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4d43e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Always the same values, do not touch. \n",
    "in_dim_GCN = 1\n",
    "out_dim_GCN = 1\n",
    "\n",
    "# number of max epochs \n",
    "n_epochs = 1000\n",
    "\n",
    "# Early stopping configuration\n",
    "early_stopping_patience = 50\n",
    "\n",
    "# Hyperparameters to be optimized (change this values)\n",
    "h_dropout = [0.0, 0.15, 0.3]\n",
    "h_learning_rate = [1e-3, 1e-2, 5e-2, 0.1]\n",
    "h_decay = [0, 1e-5, 1e-4, 1e-3, 1e-2]\n",
    "h_hid_lay = [4, 8, 16, 32, 64]\n",
    "h_layers = [1, 2, 3, 4, 5, 6]\n",
    "seed = [42, 76, 124, 163, 192, 205, 221, 245, 293]\n",
    "\n",
    "fc_layer = [[1120, out_dim_GCN]]\n",
    "\n",
    "\n",
    "# Parameters to define type of GCNN and type of output.\n",
    "typeGCN = \"standard_gcnn\"\n",
    "K = [0]\n",
    "\n",
    "\n",
    "params = {# Hyperparameters\n",
    "         'h_layers':h_layers, 'n_epochs':n_epochs, \n",
    "          'h_dropout': h_dropout, 'h_learning_rate': h_learning_rate, \n",
    "          'h_decay':h_decay, 'h_hid_lay': h_hid_lay, 'K':K,\n",
    "          'fc_layer': fc_layer,\n",
    "          # seed to set initialization hyperparameters\n",
    "          'seed': seed, \n",
    "          # Type of output GCN\n",
    "          'typeGCN': typeGCN,\n",
    "          # Dimensions of GCN (input/output)\n",
    "          'in_dim_GCN': in_dim_GCN, 'out_dim_GCN': out_dim_GCN,\n",
    "          # Patiente\n",
    "          'early_stopping_patience':early_stopping_patience}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be017052",
   "metadata": {},
   "source": [
    "## Way to build the network: \n",
    "### Product Graph of the same adjacency matrix obtained by dtw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca30035",
   "metadata": {},
   "outputs": [],
   "source": [
    "way_to_build_graph = \"dtw-hgd\"\n",
    "# Others ways: correlations; smoothness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6306bdd",
   "metadata": {},
   "source": [
    "## Train phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a668f81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "\n",
    "best_result_by_split = {}\n",
    "train_times_by_split = {}\n",
    "\n",
    "for carp in range(len(folders)):\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # Load data for the current folder (split)\n",
    "    X_train_vec, X_val_vec, X_test_vec, y_train, y_val, y_test = utils.load_data(norm, device, folders[carp])\n",
    "    A = pd.read_csv(\"../../step2_graphRepresentation/\" + way_to_build_graph + \"/\" + folders[carp] + \"/ProdGraph_Xtr_\" + norm + \"_th_0.975.csv\")\n",
    "    A = torch.tensor(np.array(A), dtype=torch.float32)\n",
    "\n",
    "    print(f\"\\n===========> TRAIN-VAL PHASE for folder {folders[carp]} ==================\")\n",
    "\n",
    "    # Measure training time\n",
    "    start_time = time.time()\n",
    "    bestHyperparameters = utils.train_val_phase(A, X_train_vec, X_val_vec, y_train, y_val, params, device)\n",
    "    end_time = time.time()\n",
    "    elapsed_time = round(end_time - start_time, 2)\n",
    "\n",
    "    print(f\"<========== END TRAIN-VAL PHASE for folder {folders[carp]} | Elapsed time: {elapsed_time:.2f} seconds ==============\\n\")\n",
    "\n",
    "    # Store best hyperparameters and training time\n",
    "    best_result_by_split[folders[carp]] = {\n",
    "        \"best_hyperparameters\": bestHyperparameters,\n",
    "    }\n",
    "\n",
    "# Save hyperparameters and training times\n",
    "path_hyper = \"../hyperparameters/\" + way_to_build_graph + \"/#E2.1-ProductGraph_th_0.975.json\"\n",
    "utils.saveBestHyperparameters(best_result_by_split, path_hyper)\n",
    "\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a66f983",
   "metadata": {},
   "source": [
    "## Validation phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282fbb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "\n",
    "folders = [\"s1\", \"s2\", \"s3\"]\n",
    "best_result_by_split = utils.loadBestHyperparameters(\n",
    "    \"../hyperparameters/\" + way_to_build_graph + \"/#E2.1-ProductGraph_th_0.975.json\"\n",
    ")\n",
    "\n",
    "typeOfGraph = \"ProdGraph\"\n",
    "path_A = typeOfGraph + \"_Xtr_\" + norm + \"_th_0.975.csv\"\n",
    "\n",
    "# Dictionary to store inference times\n",
    "inference_times_by_split = {}\n",
    "\n",
    "# Initialize containers\n",
    "results = {}\n",
    "importance_nodes = {}\n",
    "fc_classifiers = {}\n",
    "gnn_models = {}\n",
    "\n",
    "# Inference loop per split\n",
    "for folder in folders:\n",
    "\n",
    "    start_time = time.time()\n",
    "    res, imp_nodes, fc_cls, gnn_mod = utils.val_model(\n",
    "        {folder: best_result_by_split[folder]},\n",
    "        typeOfGraph, params, [folder], norm, device, path_A, way_to_build_graph\n",
    "    )\n",
    "    end_time = time.time()\n",
    "    elapsed = round(end_time - start_time, 2)\n",
    "\n",
    "    inference_times_by_split[folder] = {\n",
    "        \"inference_time_seconds\": elapsed\n",
    "    }\n",
    "\n",
    "    # Store results\n",
    "    for k in res:\n",
    "        if k not in results:\n",
    "            results[k] = []\n",
    "        results[k].append(res[k][0])\n",
    "    importance_nodes[folder] = imp_nodes\n",
    "    fc_classifiers[folder] = fc_cls\n",
    "    gnn_models[folder] = gnn_mod\n",
    "\n",
    "# Display results per split\n",
    "keys = list(results.keys())\n",
    "for c in range(len(folders)):\n",
    "    print(\"================= SPLIT \" + str(folders[c]) + \" ===================\")\n",
    "    for k in keys:\n",
    "        print(k + \": \" + str(np.round(results[k][c] * 100, 2)))\n",
    "\n",
    "# Print aggregated metrics and build LaTeX result string\n",
    "print()\n",
    "str_result = \"\"\n",
    "for i in range(len(keys)):\n",
    "    average = np.mean(results[keys[i]])\n",
    "    std = np.std(results[keys[i]])\n",
    "    print(keys[i] + \": \" + str(np.round(average * 100, 2)) + \" +- \" + str(np.round(std * 100, 2)))\n",
    "    if i in [1, 2, 4]:  # adjust index if needed to match acc, auc, auc_pr\n",
    "        str_result += str(np.round(average * 100, 2)) + \" +- \" + str(np.round(std * 100, 2)) + \" & \"\n",
    "    elif i == 3:\n",
    "        str_result += str(np.round(average * 100, 2)) + \" +- \" + str(np.round(std * 100, 2)) + \" \\\\\\ \"\n",
    "\n",
    "print(\"\\n\", str_result)\n",
    "\n",
    "# Save inference times\n",
    "path_times = \"../hyperparameters/\" + way_to_build_graph + \"/#E2.1-InferenceTimes_th_0.975.json\"\n",
    "with open(path_times, 'w') as f:\n",
    "    json.dump(inference_times_by_split, f, indent=4)\n",
    "\n",
    "print(f\"\\nInference times saved to: {path_times}\")\n",
    "\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f4c7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "77.77 +- 1.71 & 75.47 +- 2.67 & 72.73 +- 3.24 & 46.7 +- 5.26 \\\\ "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
